#!/usr/bin/env python3
"""
å»é‡è„šæœ¬ï¼šæ¸…ç† zhihu_content è¡¨ä¸­é‡å¤çš„ content_id è®°å½•ã€‚
ä¿ç•™æ¯ç»„é‡å¤è®°å½•ä¸­ id æœ€å°çš„é‚£æ¡ï¼ˆå³æœ€æ—©å…¥åº“çš„ï¼‰ã€‚

ä½¿ç”¨æ–¹æ³•:
    # åªæŸ¥çœ‹é‡å¤æƒ…å†µï¼ˆä¸åˆ é™¤ï¼‰
    python scripts/dedupe_articles.py --dry-run

    # æ‰§è¡Œåˆ é™¤
    python scripts/dedupe_articles.py
"""

import argparse
import os
import sys

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from sqlalchemy import create_engine, text


def get_database_url():
    """è·å–æ•°æ®åº“è¿æ¥ URL."""
    # å°è¯•ä»ç¯å¢ƒå˜é‡è·å–
    db_url = os.getenv("DATABASE_URL")
    if db_url:
        return db_url

    # å°è¯•ä» .env æ–‡ä»¶è¯»å–
    env_file = os.path.join(os.path.dirname(os.path.dirname(__file__)), "backend", ".env")
    if os.path.exists(env_file):
        with open(env_file) as f:
            for line in f:
                if line.startswith("DATABASE_URL="):
                    return line.strip().split("=", 1)[1].strip('"').strip("'")

    # é»˜è®¤ SQLite
    return "sqlite:///./data.db"


def find_duplicates(engine):
    """æŸ¥æ‰¾é‡å¤çš„ content_id."""
    with engine.connect() as conn:
        result = conn.execute(text("""
            SELECT content_id, COUNT(*) as cnt
            FROM zhihu_content
            GROUP BY content_id
            HAVING COUNT(*) > 1
            ORDER BY cnt DESC
        """))
        return list(result.fetchall())


def get_duplicate_details(engine, content_id):
    """è·å–æŸä¸ª content_id çš„æ‰€æœ‰é‡å¤è®°å½•è¯¦æƒ…."""
    with engine.connect() as conn:
        result = conn.execute(text("""
            SELECT id, content_id, title, author_name, created_time
            FROM zhihu_content
            WHERE content_id = :content_id
            ORDER BY id
        """), {"content_id": content_id})
        return list(result.fetchall())


def delete_duplicates(engine, dry_run=True):
    """åˆ é™¤é‡å¤è®°å½•ï¼Œä¿ç•™æ¯ç»„ä¸­ id æœ€å°çš„."""
    duplicates = find_duplicates(engine)

    if not duplicates:
        print("âœ… æ²¡æœ‰å‘ç°é‡å¤è®°å½•ï¼")
        return 0

    print(f"\nğŸ” å‘ç° {len(duplicates)} ä¸ª content_id å­˜åœ¨é‡å¤")
    print("-" * 60)

    total_to_delete = 0
    for content_id, count in duplicates[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
        print(f"  content_id: {content_id} - é‡å¤ {count} æ¬¡")
        total_to_delete += count - 1  # ä¿ç•™1æ¡

    if len(duplicates) > 10:
        # è®¡ç®—å‰©ä½™çš„
        remaining = sum(cnt - 1 for _, cnt in duplicates[10:])
        total_to_delete += remaining
        print(f"  ... è¿˜æœ‰ {len(duplicates) - 10} ä¸ªé‡å¤çš„ content_id")

    print("-" * 60)
    print(f"ğŸ“Š æ€»å…±éœ€è¦åˆ é™¤ {total_to_delete} æ¡é‡å¤è®°å½•")

    if dry_run:
        print("\nâš ï¸  DRY RUN æ¨¡å¼ - ä¸ä¼šæ‰§è¡Œåˆ é™¤æ“ä½œ")
        print("   ä½¿ç”¨ --execute å‚æ•°æ¥å®é™…æ‰§è¡Œåˆ é™¤")
        return total_to_delete

    # æ‰§è¡Œåˆ é™¤
    print("\nğŸ—‘ï¸  å¼€å§‹åˆ é™¤é‡å¤è®°å½•...")

    with engine.begin() as conn:
        # ä½¿ç”¨å­æŸ¥è¯¢åˆ é™¤ï¼Œä¿ç•™æ¯ç»„ä¸­ id æœ€å°çš„è®°å½•
        # PostgreSQL è¯­æ³•
        db_url = str(engine.url)
        if "postgresql" in db_url:
            result = conn.execute(text("""
                DELETE FROM zhihu_content
                WHERE id NOT IN (
                    SELECT MIN(id)
                    FROM zhihu_content
                    GROUP BY content_id
                )
            """))
        else:
            # SQLite è¯­æ³•
            result = conn.execute(text("""
                DELETE FROM zhihu_content
                WHERE id NOT IN (
                    SELECT MIN(id)
                    FROM zhihu_content
                    GROUP BY content_id
                )
            """))

        deleted = result.rowcount
        print(f"âœ… æˆåŠŸåˆ é™¤ {deleted} æ¡é‡å¤è®°å½•")
        return deleted


def main():
    parser = argparse.ArgumentParser(description="æ¸…ç† zhihu_content è¡¨ä¸­çš„é‡å¤è®°å½•")
    parser.add_argument(
        "--dry-run",
        action="store_true",
        default=True,
        help="åªæ˜¾ç¤ºé‡å¤æƒ…å†µï¼Œä¸æ‰§è¡Œåˆ é™¤ï¼ˆé»˜è®¤ï¼‰"
    )
    parser.add_argument(
        "--execute",
        action="store_true",
        help="å®é™…æ‰§è¡Œåˆ é™¤æ“ä½œ"
    )
    parser.add_argument(
        "--show-details",
        type=str,
        help="æ˜¾ç¤ºæŒ‡å®š content_id çš„é‡å¤è®°å½•è¯¦æƒ…"
    )

    args = parser.parse_args()

    db_url = get_database_url()
    print(f"ğŸ“¦ æ•°æ®åº“: {db_url[:50]}...")

    engine = create_engine(db_url)

    if args.show_details:
        details = get_duplicate_details(engine, args.show_details)
        if details:
            print(f"\n content_id={args.show_details} çš„è®°å½•:")
            for row in details:
                print(f"  id={row[0]}, title={row[2][:30] if row[2] else 'N/A'}..., author={row[3]}")
        else:
            print(f"æœªæ‰¾åˆ° content_id={args.show_details}")
        return

    dry_run = not args.execute
    delete_duplicates(engine, dry_run=dry_run)


if __name__ == "__main__":
    main()
