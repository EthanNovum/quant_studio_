#!/usr/bin/env python3
"""
æœ¬åœ°æ•°æ®ä¸Šä¼ è„šæœ¬ - å°† SQLite æ•°æ®ä¸Šä¼ åˆ°è¿œç¨‹ PostgreSQL æœåŠ¡å™¨

åŠŸèƒ½:
  - ä»æœ¬åœ° SQLite è¯»å–æ–‡ç« å’Œåˆ›ä½œè€…æ•°æ®
  - é€šè¿‡ API æ‰¹é‡ä¸Šä¼ åˆ°æœåŠ¡å™¨
  - æ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼ˆè·³è¿‡å·²å­˜åœ¨çš„æ•°æ®ï¼‰
  - æ”¯æŒåˆ†æ‰¹ä¸Šä¼ ï¼Œé¿å…è¯·æ±‚è¿‡å¤§

ç”¨æ³•:
    # ä¸Šä¼ åˆ°æœåŠ¡å™¨
    python scripts/upload_to_server.py --server https://your-server.com --token YOUR_PASSWORD

    # åªä¸Šä¼ æ–°æ•°æ®ï¼ˆæ–­ç‚¹ç»­ä¼ ï¼‰
    python scripts/upload_to_server.py --server https://your-server.com --token YOUR_PASSWORD --resume

    # æŒ‡å®šæ‰¹æ¬¡å¤§å°
    python scripts/upload_to_server.py --server https://your-server.com --token YOUR_PASSWORD --batch-size 50

    # æŸ¥çœ‹æœ¬åœ°æ•°æ®ç»Ÿè®¡
    python scripts/upload_to_server.py --stats
"""

import argparse
import json
import os
import sys
import time
from pathlib import Path
from typing import List, Set

import requests

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# é»˜è®¤é…ç½®
DEFAULT_BATCH_SIZE = 100
DEFAULT_SQLITE_PATH = Path(__file__).parent.parent / "MediaCrawler" / "database" / "sqlite_tables.db"
PROGRESS_FILE = Path(__file__).parent.parent / "data" / "upload_progress.json"


def get_sqlite_connection():
    """è·å– SQLite è¿æ¥."""
    from sqlalchemy import create_engine

    sqlite_path = os.environ.get("SQLITE_PATH", str(DEFAULT_SQLITE_PATH))
    if not Path(sqlite_path).exists():
        print(f"âŒ SQLite æ•°æ®åº“ä¸å­˜åœ¨: {sqlite_path}")
        sys.exit(1)

    return create_engine(f"sqlite:///{sqlite_path}")


def load_progress() -> dict:
    """åŠ è½½ä¸Šä¼ è¿›åº¦."""
    if PROGRESS_FILE.exists():
        try:
            with open(PROGRESS_FILE, "r") as f:
                return json.load(f)
        except Exception:
            pass
    return {"uploaded_content_ids": [], "uploaded_creator_ids": []}


def save_progress(progress: dict):
    """ä¿å­˜ä¸Šä¼ è¿›åº¦."""
    PROGRESS_FILE.parent.mkdir(exist_ok=True)
    with open(PROGRESS_FILE, "w") as f:
        json.dump(progress, f)


def fetch_articles_from_sqlite(engine, skip_ids: Set[str] = None) -> List[dict]:
    """ä» SQLite è¯»å–æ–‡ç« æ•°æ®."""
    from sqlalchemy import text

    with engine.connect() as conn:
        result = conn.execute(text("""
            SELECT
                content_id, content_type, title, content_text, content_url,
                created_time, updated_time, voteup_count, comment_count,
                user_id, user_nickname, user_avatar
            FROM zhihu_content
        """))

        articles = []
        for row in result:
            content_id = row[0]
            if skip_ids and content_id in skip_ids:
                continue

            articles.append({
                "content_id": content_id,
                "content_type": row[1] or "article",
                "title": row[2] or "",
                "content_text": row[3],
                "content_url": row[4],
                "created_time": int(row[5]) if row[5] else 0,
                "updated_time": int(row[6]) if row[6] else 0,
                "voteup_count": row[7] or 0,
                "comment_count": row[8] or 0,
                "author_id": row[9],
                "author_name": row[10],
                "author_avatar": row[11],
            })

        return articles


def fetch_creators_from_sqlite(engine, skip_ids: Set[str] = None) -> List[dict]:
    """ä» SQLite è¯»å–åˆ›ä½œè€…æ•°æ®."""
    from sqlalchemy import text

    with engine.connect() as conn:
        result = conn.execute(text("""
            SELECT
                user_id, url_token, user_nickname, user_avatar, user_link,
                gender, fans, follows, anwser_count, article_count, get_voteup_count
            FROM zhihu_creator
        """))

        creators = []
        for row in result:
            user_id = row[0]
            if skip_ids and user_id in skip_ids:
                continue

            creators.append({
                "user_id": user_id,
                "url_token": row[1] or "",
                "user_nickname": row[2] or "",
                "user_avatar": row[3],
                "user_link": row[4],
                "gender": row[5],
                "fans": row[6] or 0,
                "follows": row[7] or 0,
                "answer_count": row[8] or 0,
                "article_count": row[9] or 0,
                "voteup_count": row[10] or 0,
            })

        return creators


def get_server_status(server_url: str) -> dict:
    """è·å–æœåŠ¡å™¨å½“å‰æ•°æ®çŠ¶æ€."""
    try:
        response = requests.get(
            f"{server_url}/api/sync/upload/status",
            timeout=30,
        )
        response.raise_for_status()
        return response.json()
    except Exception as e:
        print(f"âš ï¸  æ— æ³•è·å–æœåŠ¡å™¨çŠ¶æ€: {e}")
        return {"existing_content_ids": [], "article_count": 0, "creator_count": 0}


def upload_batch(
    server_url: str,
    token: str,
    articles: List[dict],
    creators: List[dict],
    batch_id: str = None,
) -> dict:
    """ä¸Šä¼ ä¸€æ‰¹æ•°æ®åˆ°æœåŠ¡å™¨."""
    headers = {
        "Content-Type": "application/json",
        "X-Upload-Token": token,
    }

    payload = {
        "articles": articles,
        "creators": creators,
        "batch_id": batch_id,
    }

    response = requests.post(
        f"{server_url}/api/sync/upload",
        headers=headers,
        json=payload,
        timeout=120,
    )

    if response.status_code == 401:
        raise Exception("è®¤è¯å¤±è´¥: è¯·æ£€æŸ¥ --token å‚æ•°")
    elif response.status_code == 403:
        raise Exception("æƒé™ä¸è¶³: Token æ— æ•ˆ")

    response.raise_for_status()
    return response.json()


def show_stats():
    """æ˜¾ç¤ºæœ¬åœ°æ•°æ®ç»Ÿè®¡."""
    from sqlalchemy import text

    engine = get_sqlite_connection()

    with engine.connect() as conn:
        article_count = conn.execute(text("SELECT COUNT(*) FROM zhihu_content")).scalar()
        creator_count = conn.execute(text("SELECT COUNT(*) FROM zhihu_creator")).scalar()

    print("\nğŸ“Š æœ¬åœ° SQLite æ•°æ®ç»Ÿè®¡")
    print("-" * 30)
    print(f"  æ–‡ç« æ•°é‡: {article_count}")
    print(f"  åˆ›ä½œè€…æ•°é‡: {creator_count}")
    print(f"  æ•°æ®åº“è·¯å¾„: {DEFAULT_SQLITE_PATH}")

    # æ˜¾ç¤ºä¸Šä¼ è¿›åº¦
    progress = load_progress()
    uploaded_articles = len(progress.get("uploaded_content_ids", []))
    uploaded_creators = len(progress.get("uploaded_creator_ids", []))

    if uploaded_articles > 0 or uploaded_creators > 0:
        print("\nğŸ“¤ ä¸Šä¼ è¿›åº¦")
        print("-" * 30)
        print(f"  å·²ä¸Šä¼ æ–‡ç« : {uploaded_articles}")
        print(f"  å·²ä¸Šä¼ åˆ›ä½œè€…: {uploaded_creators}")


def main():
    parser = argparse.ArgumentParser(description="æœ¬åœ°æ•°æ®ä¸Šä¼ åˆ°è¿œç¨‹æœåŠ¡å™¨")
    parser.add_argument("--server", "-s", type=str, help="æœåŠ¡å™¨åœ°å€ (å¦‚ https://your-server.com)")
    parser.add_argument("--token", "-t", type=str, help="ä¸Šä¼ è®¤è¯ä»¤ç‰Œ (AUTH_PASSWORD)")
    parser.add_argument("--batch-size", "-b", type=int, default=DEFAULT_BATCH_SIZE, help="æ¯æ‰¹ä¸Šä¼ æ•°é‡")
    parser.add_argument("--resume", "-r", action="store_true", help="æ–­ç‚¹ç»­ä¼ ï¼ˆè·³è¿‡å·²ä¸Šä¼ çš„æ•°æ®ï¼‰")
    parser.add_argument("--stats", action="store_true", help="æ˜¾ç¤ºæœ¬åœ°æ•°æ®ç»Ÿè®¡")
    parser.add_argument("--clear-progress", action="store_true", help="æ¸…é™¤ä¸Šä¼ è¿›åº¦è®°å½•")

    args = parser.parse_args()

    if args.stats:
        show_stats()
        return

    if args.clear_progress:
        if PROGRESS_FILE.exists():
            PROGRESS_FILE.unlink()
            print("âœ… å·²æ¸…é™¤ä¸Šä¼ è¿›åº¦è®°å½•")
        else:
            print("â„¹ï¸  æ²¡æœ‰è¿›åº¦è®°å½•éœ€è¦æ¸…é™¤")
        return

    if not args.server or not args.token:
        parser.print_help()
        print("\nâŒ è¯·æä¾› --server å’Œ --token å‚æ•°")
        sys.exit(1)

    server_url = args.server.rstrip("/")

    print(f"ğŸ”— æœåŠ¡å™¨: {server_url}")
    print(f"ğŸ“¦ æ‰¹æ¬¡å¤§å°: {args.batch_size}")
    print(f"ğŸ”„ æ–­ç‚¹ç»­ä¼ : {'æ˜¯' if args.resume else 'å¦'}")
    print()

    # è·å–æœåŠ¡å™¨çŠ¶æ€
    print("ğŸ“¡ æ­£åœ¨è·å–æœåŠ¡å™¨çŠ¶æ€...")
    server_status = get_server_status(server_url)
    existing_ids = set(server_status.get("existing_content_ids", []))
    print(f"   æœåŠ¡å™¨å·²æœ‰æ–‡ç« : {server_status.get('article_count', 0)}")
    print(f"   æœåŠ¡å™¨å·²æœ‰åˆ›ä½œè€…: {server_status.get('creator_count', 0)}")

    # åŠ è½½æœ¬åœ°è¿›åº¦
    progress = load_progress() if args.resume else {"uploaded_content_ids": [], "uploaded_creator_ids": []}
    local_uploaded_ids = set(progress.get("uploaded_content_ids", []))
    local_uploaded_creator_ids = set(progress.get("uploaded_creator_ids", []))

    # åˆå¹¶è·³è¿‡çš„ ID
    skip_article_ids = existing_ids | local_uploaded_ids
    skip_creator_ids = set(local_uploaded_creator_ids)

    if args.resume:
        print(f"   æœ¬åœ°å·²ä¸Šä¼ æ–‡ç« : {len(local_uploaded_ids)}")
        print(f"   æœ¬åœ°å·²ä¸Šä¼ åˆ›ä½œè€…: {len(local_uploaded_creator_ids)}")

    print()

    # è¯»å–æœ¬åœ°æ•°æ®
    print("ğŸ“– æ­£åœ¨è¯»å–æœ¬åœ° SQLite æ•°æ®...")
    engine = get_sqlite_connection()

    articles = fetch_articles_from_sqlite(engine, skip_article_ids if args.resume else None)
    creators = fetch_creators_from_sqlite(engine, skip_creator_ids if args.resume else None)

    print(f"   å¾…ä¸Šä¼ æ–‡ç« : {len(articles)}")
    print(f"   å¾…ä¸Šä¼ åˆ›ä½œè€…: {len(creators)}")
    print()

    if not articles and not creators:
        print("âœ… æ²¡æœ‰æ–°æ•°æ®éœ€è¦ä¸Šä¼ !")
        return

    # åˆ†æ‰¹ä¸Šä¼ 
    total_articles = len(articles)
    total_creators = len(creators)
    batch_size = args.batch_size

    total_inserted = 0
    total_updated = 0

    # ä¸Šä¼ æ–‡ç« 
    if articles:
        print("ğŸ“¤ å¼€å§‹ä¸Šä¼ æ–‡ç« ...")
        for i in range(0, total_articles, batch_size):
            batch = articles[i:i + batch_size]
            batch_num = i // batch_size + 1
            total_batches = (total_articles + batch_size - 1) // batch_size

            try:
                result = upload_batch(
                    server_url,
                    args.token,
                    articles=batch,
                    creators=[],
                    batch_id=f"articles-{batch_num}",
                )

                total_inserted += result.get("articles_inserted", 0)
                total_updated += result.get("articles_updated", 0)

                # ä¿å­˜è¿›åº¦
                for item in batch:
                    progress["uploaded_content_ids"].append(item["content_id"])
                save_progress(progress)

                print(f"   æ‰¹æ¬¡ {batch_num}/{total_batches}: +{result.get('articles_inserted', 0)} ~{result.get('articles_updated', 0)}")

            except Exception as e:
                print(f"   âŒ æ‰¹æ¬¡ {batch_num} å¤±è´¥: {e}")
                print(f"   ğŸ’¾ è¿›åº¦å·²ä¿å­˜ï¼Œå¯ä½¿ç”¨ --resume ç»§ç»­")
                sys.exit(1)

            # çŸ­æš‚ä¼‘çœ é¿å…è¯·æ±‚è¿‡å¿«
            time.sleep(0.1)

    # ä¸Šä¼ åˆ›ä½œè€…
    if creators:
        print("\nğŸ“¤ å¼€å§‹ä¸Šä¼ åˆ›ä½œè€…...")
        for i in range(0, total_creators, batch_size):
            batch = creators[i:i + batch_size]
            batch_num = i // batch_size + 1
            total_batches = (total_creators + batch_size - 1) // batch_size

            try:
                result = upload_batch(
                    server_url,
                    args.token,
                    articles=[],
                    creators=batch,
                    batch_id=f"creators-{batch_num}",
                )

                # ä¿å­˜è¿›åº¦
                for item in batch:
                    progress["uploaded_creator_ids"].append(item["user_id"])
                save_progress(progress)

                print(f"   æ‰¹æ¬¡ {batch_num}/{total_batches}: +{result.get('creators_inserted', 0)} ~{result.get('creators_updated', 0)}")

            except Exception as e:
                print(f"   âŒ æ‰¹æ¬¡ {batch_num} å¤±è´¥: {e}")
                print(f"   ğŸ’¾ è¿›åº¦å·²ä¿å­˜ï¼Œå¯ä½¿ç”¨ --resume ç»§ç»­")
                sys.exit(1)

            time.sleep(0.1)

    print("\n" + "=" * 40)
    print("âœ… ä¸Šä¼ å®Œæˆ!")
    print(f"   æ–‡ç« : æ–°å¢ {total_inserted}, æ›´æ–° {total_updated}")
    print(f"   åˆ›ä½œè€…: {len(creators)} æ¡å·²å¤„ç†")


if __name__ == "__main__":
    main()
